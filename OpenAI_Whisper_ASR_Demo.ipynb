{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Web App Demonstrating OpenAI's Whisper Speech Recognition Model\n",
        "\n",
        "This is a Colab notebook that allows you to upload audio files to [OpenAI's free Whisper speech recognition model](https://openai.com/blog/whisper/).\n",
        "\n",
        "To use it, choose `Runtime->Run All` from the Colab menu. You can upload your own audio samples using the folder icon on the left of this page. That gives you access to a file system you can upload to by dragging files into it. You can see examples of how to run the transcription in a couple of the cells below.\n",
        "You can also save the file in your google drive provided we have to give access to save it in our gdrive."
      ],
      "metadata": {
        "id": "Lbja1jB3vDOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the Whisper Code"
      ],
      "metadata": {
        "id": "kosakhNmxb7A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsJUxc0aRsAf"
      },
      "outputs": [],
      "source": [
        "! pip install git+https://github.com/openai/whisper.git -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the ML Model"
      ],
      "metadata": {
        "id": "AtAvuKSJxhNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n"
      ],
      "metadata": {
        "id": "Kr5faKybKi4p"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check we have a GPU\n",
        "\n",
        "You should see the output `device(type='cuda', index=0)` below. If you don't, you may be on a CPU-only Colab instance which will run more slowly. Go to `Runtime->Change Runtime Type` to fix this."
      ],
      "metadata": {
        "id": "e200RNNlxn5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.device"
      ],
      "metadata": {
        "id": "u_6_s2iHboR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Transcribe Function\n",
        "\n",
        "Now we've loaded the model, and have the code, this is the function that takes an audio file path as an input and returns the recognized text (and logs what it thinks the language is)."
      ],
      "metadata": {
        "id": "QwLTZtubySoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(audio):\n",
        "\n",
        "    # load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # make log-Mel spectrogram and move to the same device as the model\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # detect the spoken language\n",
        "    _, probs = model.detect_language(mel)\n",
        "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
        "\n",
        "    # decode the audio\n",
        "    options = whisper.DecodingOptions()\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    return result.text\n"
      ],
      "metadata": {
        "id": "JtTvvQQPcOZZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "ILFOYNnTcYe8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File Upload Facility\n",
        "\n",
        "Upload your file in the prompt."
      ],
      "metadata": {
        "id": "2tHwfOG-zlY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "id": "y2Zid2MKdPxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = next(iter(uploaded))\n",
        "print(filename)\n",
        "\n",
        "Audio(filename)\n",
        "\n",
        "hard_text = transcribe(filename)\n",
        "print(hard_text)"
      ],
      "metadata": {
        "id": "nfP98XflppB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "from IPython.display import Audio, display\n",
        "import os\n",
        "\n",
        "# Load audio\n",
        "audio = AudioSegment.from_file(filename)\n",
        "\n",
        "# 5 seconds = 5000 ms\n",
        "frame_duration = 25 * 1000\n",
        "num_chunks = len(audio) // frame_duration + (1 if len(audio) % frame_duration > 0 else 0)\n",
        "\n",
        "# Optional: create a folder for chunks\n",
        "os.makedirs(\"chunks\", exist_ok=True)\n",
        "\n",
        "text = \"\"\n",
        "# Go through and play each chunk\n",
        "for i in range(num_chunks):\n",
        "    start = i * frame_duration\n",
        "    end = min((i + 1) * frame_duration, len(audio))\n",
        "    chunk = audio[start:end]\n",
        "\n",
        "    # Export to WAV file\n",
        "    chunk_filename = f\"chunks/chunk_{i+1}.wav\"\n",
        "    chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "    # print(f\"ðŸ”Š Playing chunk {i+1}: {start/1000:.2f}s to {end/1000:.2f}s\")\n",
        "    # display(Audio(chunk_filename))\n",
        "\n",
        "    text_chunks = transcribe(chunk_filename)\n",
        "    print(text_chunks)\n",
        "\n",
        "    text += text_chunks\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J03L03DmrXoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(text)"
      ],
      "metadata": {
        "id": "SIUNB7a7ty_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "file_path = f\"/content/drive/My Drive/{filename.split('.mp3')}.txt\"\n",
        "print(file_path)\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "  f.write(text)"
      ],
      "metadata": {
        "id": "8DWlQGVtxIHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdYnjFAVx8Nm"
      },
      "execution_count": 45,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}